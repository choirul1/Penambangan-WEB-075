# Vector Space Mode

## Metode Bag of Words

Klasifikasi teks adalah tugas untuk menetapkan kategori yang telah ditentukan ke dokumen teks bebas berdasarkan kontennya. Pendekatan tradisional menggunakan model berbasis unigram untuk klasifikasi teks. Model berbasis Unigram seperti model Bag Of Words (BOW) tidak mempertimbangkan kemunculan set kata di tingkat dokumen.

doc 1 : "Roda saya bundar"

doc 2 : "Bundar roda saya. Kalau tidak bundar, bukan roda saya"

| No Doc | Roda | Saya | Bundar | Kalau | Tidak | Bukan |
| ------ | :--- | ---- | ------ | ----- | ----- | :---- |
| 1      | 1    | 1    | 1      | 0     | 0     | 0     |
| 2      | 2    | 2    | 2      | 1     | 1     | 1     |

[1]: https://www.semanticscholar.org/paper/Text-Classification-by-Augmenting-Bag-of-Words-with-SoumyaGeorge-Joseph/f432cbc0e35e6560fc657ad6b490aa07ad901575

Code untuk melakukan perhitungan tersebut adalah sebagai berikut :

``` python
def countWord(txt):
    d = dict()
    for i  in txt.split():
        if d.get(i) == None:
            d[i] = txt.count(i)
    return d

def add_row_VSM(d):
    VSM.append([])
    for i in VSM[0]:
        if d.get(i) == None:
            VSM[-1].append(0)
        else :
            VSM[-1].append(d.pop(i));
		
    for i in d:
        VSM[0].append(i)
        for j in range(1, len(VSM)-1):
            VSM[j].append(0)
        VSM[-1].append(d.get(i))
```

[5]: https://www.semanticscholar.org/paper/Text-Classification-by-Augmenting-Bag-of-Words-with-SoumyaGeorge-Joseph/f432cbc0e35e6560fc657ad6b490aa07ad901575
## **TF - IDF**

**1. Term Frequecy**

**TF (Term Frequency)** adalah frekuensi dari kemunculan sebuah term dalam dokumen yang bersangkutan. **Semakin besar jumlah kemunculan suatu term (TF tinggi) dalam dokumen, semakin besar pula bobotnya atau akan memberikan nilai kesesuaian yang semakin besar.**

Pada **Term Frequency (TF)**, terdapat beberapa jenis formula yang dapat digunakan: 

1. **TF biner (binary TF)**, hanya memperhatikan apakah suatu kata atau term ada atau tidak dalam dokumen, jika ada diberi nilai satu (1), jika tidak diberi nilai nol (0).

2. **TF murni (raw TF)**, nilai TF diberikan berdasarkan jumlah kemunculan suatu term di dokumen. Contohnya, jika muncul lima (5) kali maka kata tersebut akan bernilai lima (5).

3. **TF logaritmik**, hal ini untuk menghindari dominansi dokumen yang mengandung sedikit term dalam query, namun mempunyai frekuensi yang tinggi.

   Rumus :TF = { 1 + log 10 (Ft,d),}



## **2. Inverse Document Frequency (IDF)**

**IDF (Inverse Document Frequency)** merupakan sebuah perhitungan dari bagaimana term didistribusikan secara luas pada koleksi dokumen yang bersangkutan.

**IDF** menunjukkan hubungan ketersediaan sebuah term dalam seluruh dokumen. **Semakin sedikit jumlah dokumen yang mengandung term yang dimaksud, maka nilai IDF semakin besar.**

Sedangkan untuk **Inverse Document Frequency (IDF)** dihitung dengan menggunakan formula sebagai berikut: 

Rumus : **IDFj = log(D/dfj)**

## **3. TF-IDV**

TF-IDV sendiri merupakan kombinasi dari TF (Term Frequence) dengan IDF (Invers Docement Frequence).

TF sendiri sama seperti metode Bag of Words yang telah kita hitung sebelumnya yang menyatakan berapa banyak keberadaan suatu term / kata dalam satu dokumen[3](https://dianwib.github.io/WEB-MINING-1/vector_space_model/#fn:3).

Sedangkan IDF menunjukkan hubungan ketersediaan sebuah term / kata dalam seluruh dokumen, oleh karena itu kita tinggal menghitung nilai IDF dari setiap Term.

TF-IDF sendiri memiliki rumus (TF x IDF).

Untuk mendapatkan IDF, pertama kita perlu mencari DF (frekuensi Dokumen). Misalnya:

doc1 : Roda Saya Bundar, bundar roda saya

doc2 : Bulan itu terlihat bundar

Maka, bisa kita ketahui:

| Kata     | Jumlah Dokumen yang memiliki kata tersebut |
| -------- | ------------------------------------------ |
| Roda     | 1                                          |
| Saya     | 1                                          |
| Bundar   | 2                                          |
| Bulan    | 1                                          |
| itu      | 1                                          |
| terlihat | 1                                          |

```python
df = list()
total_doc = bow.shape[0]
for kolom in range(len(bow[0])):
    total = 0
    for baris in range(len(bow)):
        if (bow[baris, kolom] > 0):a
            total +=1
    df.append(total)
df = np.array(df)

idf = list()
for i in df:
    tmp = 1 + log10(total_doc/(1+i))
    idf.append(tmp)
idf = np.array(idf)

tfidf = bow * idf
```

<https://informatikalogi.com/term-weighting-tf-idf/>

https://www.semanticscholar.org/paper/Text-Classification-by-Augmenting-Bag-of-Words-with-SoumyaGeorge-Joseph/f432cbc0e35e6560fc657ad6b490aa07ad901575 